{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Disaster Risk Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 220 ZIP files.\n"
     ]
    }
   ],
   "source": [
    "# Extracting Zip Files\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Define root directory\n",
    "root_dir = \"../00_data/flood_risk/\"\n",
    "\n",
    "# Extract all ZIP files\n",
    "extracted_folders = []\n",
    "\n",
    "for flood_scenario in sorted(os.listdir(root_dir)):  # e.g., \"Flood 1\", \"Flood 2\"\n",
    "    scenario_path = os.path.join(root_dir, flood_scenario)\n",
    "    \n",
    "    if os.path.isdir(scenario_path):\n",
    "        for return_period in sorted(os.listdir(scenario_path)):  # e.g., \"5yr\", \"25yr\", \"100yr\"\n",
    "            return_period_path = os.path.join(scenario_path, return_period)\n",
    "\n",
    "            if os.path.isdir(return_period_path):\n",
    "                # Extract all ZIP files inside this return period\n",
    "                for zip_file in glob.glob(os.path.join(return_period_path, \"*.zip\")):\n",
    "                    extract_folder = zip_file.replace(\".zip\", \"\")\n",
    "                    extracted_folders.append(extract_folder)\n",
    "\n",
    "                    with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
    "                        zip_ref.extractall(extract_folder)\n",
    "\n",
    "print(f\"Extracted {len(extracted_folders)} ZIP files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/AgusanDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/DavaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Kalinga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/MisamisOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Batangas.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/SultanKudarat.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Cebu.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/LanaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Catanduanes.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Aklan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/DavaoOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/MountainProvince.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Sarangani.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/MetroManila.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Leyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Misamis Oriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/SouthCotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/OrientalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Pangasinan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Maguindanao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/DavaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/OccidentalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Apayao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/DinagatIslands.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Laguna.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/NegrosOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Abra.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/SurigaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Camiguin.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/NuevaVizcaya.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/ZamboangaSibugay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/LanaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Marinduque.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/CamarinesSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/SurigaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/Benguet.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/100yr/CompostelaValley.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/5yr/Ifugao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/5yr/Masbate.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/5yr/Albay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/IlocosNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Cavite.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Isabela.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Zambales.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/LaUnion.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Pampanga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Rizal.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/IlocosSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Tarlac.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 2/25yr/Bulacan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/100yr/Samar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/100yr/IlocosNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/IlocosNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/MisamisOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/MisamisOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Isabela.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/LaUnion.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Catanduanes.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Quezon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Pampanga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Rizal.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/IlocosSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Iloilo.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Tarlac.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Cagayan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Sorsogon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 5/5yr/Bulacan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/100yr/IlocosSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/100yr/Iloilo.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/100yr/EasternSamar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/100yr/ZamboangaDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/100yr/Bulacan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Bataan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Palawan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/DavaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Samar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/ZamboangaDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Cavite.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Batangas.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/SultanKudarat.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/NegrosOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/DavaoOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Cebu.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Zambales.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Aklan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/MetroManila.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Leyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Misamis Oriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/SouthCotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Capiz.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/EasternSamar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/OrientalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Pangasinan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Maguindanao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Bohol.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Cotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/DavaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/CamarinesNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/OccidentalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Apayao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/ZamboangaDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Bukidnon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Laguna.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/NegrosOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/SurigaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/SouthernLeyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/ZamboangaSibugay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/LanaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/CamarinesSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/SurigaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/Benguet.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/CompostelaValley.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 4/5yr/NuevaEcija.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Palawan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Antique.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/MisamisOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/ZamboangaDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Cavite.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Isabela.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/DavaoOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Zambales.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/LaUnion.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/NorthernSamar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Quezon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Pampanga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Masbate.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Rizal.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Aurora.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Capiz.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Tarlac.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Bohol.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Cotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/CamarinesNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Cagayan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Bukidnon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Biliran.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Sorsogon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/SouthernLeyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Quirino.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/Batanes.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/100yr/NuevaEcija.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/5yr/LanaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/5yr/Aurora.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/5yr/DinagatIslands.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/5yr/NuevaVizcaya.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 3/25yr/Cagayan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/Bataan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/Romblon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/NegrosOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/Ifugao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/Basilan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/AgusanDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/Albay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/100yr/TawiTawi.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/5yr/Kalinga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/5yr/MountainProvince.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/5yr/Sarangani.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/5yr/Quirino.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/5yr/Marinduque.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Bataan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Palawan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/AgusanDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/DavaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Antique.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Samar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Kalinga.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/MisamisOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/MisamisOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/ZamboangaDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Batangas.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/SultanKudarat.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/NegrosOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Ifugao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/DavaoOriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Cebu.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/LanaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Catanduanes.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Quezon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Aklan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/MountainProvince.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Masbate.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/AgusanDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Sarangani.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/MetroManila.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Albay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Leyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Misamis Oriental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Aurora.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/SouthCotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Capiz.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Iloilo.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/EasternSamar.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/OrientalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Pangasinan.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Maguindanao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Bohol.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Cotabato.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/DavaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/CamarinesNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/OccidentalMindoro.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Apayao.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/DinagatIslands.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/ZamboangaDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Bukidnon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Laguna.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/NegrosOccidental.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Abra.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/SurigaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Sorsogon.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/SouthernLeyte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/NuevaVizcaya.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/ZamboangaSibugay.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/LanaoDelNorte.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Quirino.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Marinduque.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/CamarinesSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/SurigaoDelSur.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/Benguet.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/CompostelaValley.zip\n",
      "Deleted: ../00_data/flood_risk/Flood 1/25yr/NuevaEcija.zip\n",
      "All .zip files have been removed.\n"
     ]
    }
   ],
   "source": [
    "# Delete ZIP files\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the root directory\n",
    "root_dir = \"../00_data/flood_risk/\" \n",
    "\n",
    "# Find and delete all .zip files\n",
    "zip_files = glob.glob(os.path.join(root_dir, \"**\", \"*.zip\"), recursive=True)\n",
    "\n",
    "for zip_file in zip_files:\n",
    "    os.remove(zip_file)\n",
    "    print(f\"Deleted: {zip_file}\")\n",
    "\n",
    "print(\"All .zip files have been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Var                                           geometry\n",
      "0  1.0  MULTIPOLYGON (((121.52562 17.26903, 121.52534 ...\n",
      "1  2.0  MULTIPOLYGON (((121.52618 17.26985, 121.5259 1...\n",
      "2  3.0  MULTIPOLYGON (((121.52618 17.26985, 121.52618 ...\n",
      "Index(['Var', 'geometry'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Path to the specific .shp file you want to open\n",
    "shp_file = \"Flood 1/5yr/MountainProvince/MountainProvince_Flood_5year.shp\" \n",
    "\n",
    "# Load the Shapefile\n",
    "gdf = gpd.read_file(root_dir+shp_file)\n",
    "\n",
    "# Display the first few rows\n",
    "print(gdf.head())\n",
    "\n",
    "# Check the available columns\n",
    "print(gdf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Files\n",
    "The first run below was prematurely stopped because a different CRS was used for certain shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Processing: Flood 1\n",
      "  ⏳ Processing Risk Period: 5yr\n",
      "    🏙 Processing Province: Kalinga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/5yr/Kalinga/Kalinga_Flood_5year.shp\n",
      "    🏙 Processing Province: Marinduque\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/5yr/Marinduque/Marinduque_Flood_5year.shp\n",
      "    🏙 Processing Province: MountainProvince\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/5yr/MountainProvince/MountainProvince_Flood_5year.shp\n",
      "    🏙 Processing Province: Quirino\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/5yr/Quirino/Quirino_Flood_5year.shp\n",
      "    🏙 Processing Province: Sarangani\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/5yr/Sarangani/Sarangani_Flood_5year.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "  ⏳ Processing Risk Period: 25yr\n",
      "    🏙 Processing Province: Abra\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Abra/Abra_Flood_25year.shp\n",
      "    🏙 Processing Province: AgusanDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/AgusanDelNorte/AgusanDelNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: AgusanDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/AgusanDelSur/AgusanDelSur_Flood_25year.shp\n",
      "    🏙 Processing Province: Aklan\n",
      "    🏙 Processing Province: Albay\n",
      "    🏙 Processing Province: Antique\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Antique/Antique_Flood_25year.shp\n",
      "    🏙 Processing Province: Apayao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Apayao/Apayao_Flood_25year.shp\n",
      "    🏙 Processing Province: Aurora\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Aurora/Aurora_Flood_25year.shp\n",
      "    🏙 Processing Province: Bataan\n",
      "    🏙 Processing Province: Batangas\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Batangas/Batangas_Flood_25yr.shp\n",
      "    🏙 Processing Province: Benguet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Benguet/Benguet_Flood_25year.shp\n",
      "    🏙 Processing Province: Bohol\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Bohol/Bohol_Flood_25year.shp\n",
      "    🏙 Processing Province: Bukidnon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Bukidnon/Bukidnon_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "    🏙 Processing Province: CamarinesNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/CamarinesNorte/CamarinesNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: CamarinesSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/CamarinesSur/CamarinesSur_Flood_25yr.shp\n",
      "    🏙 Processing Province: Capiz\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Capiz/Capiz_Flood_25year.shp\n",
      "    🏙 Processing Province: Catanduanes\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Catanduanes/Catanduanes_Flood_25year.shp\n",
      "    🏙 Processing Province: Cebu\n",
      "    🏙 Processing Province: CompostelaValley\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/CompostelaValley/CompostelaValley_Flood_25year.shp\n",
      "    🏙 Processing Province: Cotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Cotabato/Cotabato_Flood_25year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Cotabato/SouthCotabato_Flood_25year.shp\n",
      "    🏙 Processing Province: DavaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/DavaoDelNorte/DavaoDelNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: DavaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/DavaoDelSur/DavaoDelSur_Flood_25year.shp\n",
      "    🏙 Processing Province: DavaoOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/DavaoOriental/DavaoOriental_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "    🏙 Processing Province: DinagatIslands\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/DinagatIslands/DinagatIslands_Flood_25year.shp\n",
      "    🏙 Processing Province: EasternSamar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/EasternSamar/EasternSamar_Flood_25year.shp\n",
      "    🏙 Processing Province: Ifugao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Ifugao/Ifugao_Flood_25year.shp\n",
      "    🏙 Processing Province: Iloilo\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Iloilo/Iloilo_Flood_25year.shp\n",
      "    🏙 Processing Province: Kalinga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Kalinga/Kalinga_Flood_25year.shp\n",
      "    🏙 Processing Province: Laguna\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Laguna/Laguna_Flood_25year.shp\n",
      "    🏙 Processing Province: LanaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/LanaoDelNorte/LanaoDelNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: LanaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/LanaoDelSur/LanaoDelSur_Flood_25year.shp\n",
      "    🏙 Processing Province: Leyte\n",
      "    🏙 Processing Province: Maguindanao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Maguindanao/Maguindanao_Flood_25year.shp\n",
      "    🏙 Processing Province: Marinduque\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Marinduque/Marinduque_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "    🏙 Processing Province: Masbate\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Masbate/Masbate_Flood_25year.shp\n",
      "    🏙 Processing Province: MetroManila\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/MetroManila/MetroManila_Flood_25year.shp\n",
      "    🏙 Processing Province: Misamis Oriental\n",
      "    🏙 Processing Province: MisamisOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/MisamisOccidental/MisamisOccidental_Flood_25year.shp\n",
      "    🏙 Processing Province: MisamisOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/MisamisOriental/MisamisOriental_Flood_25year.shp\n",
      "    🏙 Processing Province: MountainProvince\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/MountainProvince/MountainProvince_Flood_25year.shp\n",
      "    🏙 Processing Province: NegrosOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/NegrosOccidental/NegrosOccidental_Flood_25year.shp\n",
      "    🏙 Processing Province: NegrosOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/NegrosOriental/NegrosOriental_Flood_25year.shp\n",
      "    🏙 Processing Province: NuevaEcija\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/NuevaEcija/NuevaEcija_Flood_25year.shp\n",
      "    🏙 Processing Province: NuevaVizcaya\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/NuevaVizcaya/NuevaVizcaya_Flood_25year.shp\n",
      "    🏙 Processing Province: OccidentalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/OccidentalMindoro/OccidentalMindoro_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "    🏙 Processing Province: OrientalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/OrientalMindoro/OrientalMindoro_Flood_25year.shp\n",
      "    🏙 Processing Province: Palawan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Palawan/Palawan_Flood_25year.shp\n",
      "    🏙 Processing Province: Pangasinan\n",
      "    🏙 Processing Province: Quezon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Quezon/Quezon_Flood_25year.shp\n",
      "    🏙 Processing Province: Quirino\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Quirino/Quirino_Flood_25year.shp\n",
      "    🏙 Processing Province: Samar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Samar/EasternSamar_Flood_25year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Samar/Samar_Flood_25year.shp\n",
      "    🏙 Processing Province: Sarangani\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Sarangani/Sarangani_Flood_25year.shp\n",
      "    🏙 Processing Province: Sorsogon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Sorsogon/Sorsogon_Flood_25year.shp\n",
      "    🏙 Processing Province: SouthCotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/SouthCotabato/SouthCotabato_Flood_25year.shp\n",
      "    🏙 Processing Province: SouthernLeyte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/SouthernLeyte/SouthernLeyte_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "    🏙 Processing Province: SultanKudarat\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/SultanKudarat/SultanKudarat_Flood_25year.shp\n",
      "    🏙 Processing Province: SurigaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/SurigaoDelNorte/SurigaoDelNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: SurigaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/SurigaoDelSur/SurigaoDelSur_Flood_25year.shp\n",
      "    🏙 Processing Province: ZamboangaDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/ZamboangaDelNorte/ZamboangaDelNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: ZamboangaDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/ZamboangaDelSur/ZamboangaDelSur_Flood_25year.shp\n",
      "    🏙 Processing Province: ZamboangaSibugay\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/ZamboangaSibugay/ZamboangaSibugay_Flood_25year.shp\n",
      "      ✅ Final save for 25yr at ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "    🏙 Processing Province: AgusanDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/AgusanDelSur/AgusanDelSur_Flood_100year.shp\n",
      "    🏙 Processing Province: Albay\n",
      "    🏙 Processing Province: Basilan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/Basilan/Basilan_Flood_100year.shp\n",
      "    🏙 Processing Province: Bataan\n",
      "    🏙 Processing Province: Ifugao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/Ifugao/Ifugao_Flood_100year.shp\n",
      "    🏙 Processing Province: NegrosOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/NegrosOriental/NegrosOriental_Flood_100year.shp\n",
      "    🏙 Processing Province: Romblon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/Romblon/Romblon_Flood_100year.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "📂 Processing: Flood 2\n",
      "  ⏳ Processing Risk Period: 5yr\n",
      "    🏙 Processing Province: Albay\n",
      "    🏙 Processing Province: Ifugao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/5yr/Ifugao/Ifugao_Flood_5year.shp\n",
      "    🏙 Processing Province: Masbate\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/5yr/Masbate/Masbate_Flood_5year.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyogrio/raw.py:198: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured 3D Polygon' is converted to 'Polygon Z'\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "  ⏳ Processing Risk Period: 25yr\n",
      "    🏙 Processing Province: Bulacan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Bulacan/Bulacan_Flood_25year.shp\n",
      "    🏙 Processing Province: Cavite\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Cavite/Cavite_Flood_25year.shp\n",
      "    🏙 Processing Province: IlocosNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/IlocosNorte/IlocosNorte_Flood_25year.shp\n",
      "    🏙 Processing Province: IlocosSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/IlocosSur/IlocosSur_Flood_25year.shp\n",
      "    🏙 Processing Province: Isabela\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Isabela/Isabela_Flood_25year.shp\n",
      "    🏙 Processing Province: LaUnion\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/LaUnion/LaUnion_Flood_25year.shp\n",
      "    🏙 Processing Province: Pampanga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Pampanga/Pampanga_Flood_25year.shp\n",
      "    🏙 Processing Province: Rizal\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Rizal/Rizal_Flood_25year.shp\n",
      "    🏙 Processing Province: Tarlac\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Tarlac/Tarlac_Flood_25year.shp\n",
      "    🏙 Processing Province: Zambales\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/25yr/Zambales/Zambales_Flood_25year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "    🏙 Processing Province: Abra\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Abra/Abra_Flood_100year.shp\n",
      "    🏙 Processing Province: AgusanDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/AgusanDelNorte/AgusanDelNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: Aklan\n",
      "    🏙 Processing Province: Apayao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Apayao/Apayao_Flood_100year.shp\n",
      "    🏙 Processing Province: Batangas\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Batangas/Batangas_Flood_100yr.shp\n",
      "    🏙 Processing Province: Benguet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Benguet/Benguet_Flood_100year.shp\n",
      "    🏙 Processing Province: CamarinesSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/CamarinesSur/CamarinesSur_Flood_100yr.shp\n",
      "    🏙 Processing Province: Camiguin\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Camiguin/Camiguin_Flood_100year.shp\n",
      "    🏙 Processing Province: Catanduanes\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Catanduanes/Catanduanes_Flood_100year.shp\n",
      "    🏙 Processing Province: Cebu\n",
      "    🏙 Processing Province: CompostelaValley\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/CompostelaValley/CompostelaValley_Flood_100year.shp\n",
      "    🏙 Processing Province: DavaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DavaoDelNorte/DavaoDelNorte_Flood_100year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "    🏙 Processing Province: DavaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DavaoDelSur/DavaoDelSur_Flood_100year.shp\n",
      "    🏙 Processing Province: DavaoOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DavaoOccidental/DavaoOccidental_Flood_100year.shp\n",
      "    🏙 Processing Province: DinagatIslands\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DinagatIslands/DinagatIslands_Flood_100year.shp\n",
      "    🏙 Processing Province: Kalinga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Kalinga/Kalinga_Flood_100year.shp\n",
      "    🏙 Processing Province: Laguna\n",
      "    🏙 Processing Province: LanaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/LanaoDelNorte/LanaoDelNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: LanaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/LanaoDelSur/LanaoDelSur_Flood_100year.shp\n",
      "    🏙 Processing Province: Leyte\n",
      "    🏙 Processing Province: Maguindanao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Maguindanao/Maguindanao_Flood_100year.shp\n",
      "    🏙 Processing Province: Marinduque\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Marinduque/Marinduque_Flood_100year.shp\n",
      "    🏙 Processing Province: MetroManila\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/MetroManila/MetroManila_Flood_100year.shp\n",
      "    🏙 Processing Province: Misamis Oriental\n",
      "    🏙 Processing Province: MisamisOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/MisamisOccidental/MisamisOccidental_Flood_100year.shp\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot determine common CRS for concatenation inputs, got ['WGS 84', 'WGS 84 / UTM zone 51N']. Use `to_crs()` to transform geometries to the same CRS before merging.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m province_counter \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m SAVE_INTERVAL:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_gdfs:\n\u001b[0;32m---> 81\u001b[0m         combined_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_gdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     82\u001b[0m         parquet_path \u001b[38;5;241m=\u001b[39m output_files[risk_period]\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# Append by reading old data and merging before saving\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/concat.py:180\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    177\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mea_compat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_block_shape(values, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/concat.py:83\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat_same_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_eas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_concat_same_type(to_concat_eas)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/geopandas/array.py:1638\u001b[0m, in \u001b[0;36mGeometryArray._concat_same_type\u001b[0;34m(cls, to_concat)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03mConcatenate multiple array\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03mExtensionArray\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([ga\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;28;01mfor\u001b[39;00m ga \u001b[38;5;129;01min\u001b[39;00m to_concat])\n\u001b[0;32m-> 1638\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(data, crs\u001b[38;5;241m=\u001b[39m\u001b[43m_get_common_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/geopandas/array.py:1737\u001b[0m, in \u001b[0;36m_get_common_crs\u001b[0;34m(arr_seq)\u001b[0m\n\u001b[1;32m   1729\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRS not set for some of the concatenation inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1731\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms CRS as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(the single non-null crs provided).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1733\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1734\u001b[0m         )\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m crs_not_none[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1737\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine common CRS for concatenation inputs, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1739\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `to_crs()` to transform geometries to the same CRS before merging.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1740\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot determine common CRS for concatenation inputs, got ['WGS 84', 'WGS 84 / UTM zone 51N']. Use `to_crs()` to transform geometries to the same CRS before merging."
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Root directories\n",
    "root_dir = \"../00_data/flood_risk/\"\n",
    "output_path = \"../01_processed_data/flood_risk/\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Paths for output files\n",
    "output_files = {\n",
    "    \"5yr\": os.path.join(output_path, \"FloodRisk_5yr.parquet\"),\n",
    "    \"25yr\": os.path.join(output_path, \"FloodRisk_25yr.parquet\"),\n",
    "    \"100yr\": os.path.join(output_path, \"FloodRisk_100yr.parquet\"),\n",
    "}\n",
    "\n",
    "# Processing settings\n",
    "SAVE_INTERVAL = 10  # Save every 10 provinces\n",
    "processed_count = 0\n",
    "test_limit = None  # Set to an integer (e.g., 20) for testing, or None for full processing\n",
    "\n",
    "# Loop through each Flood folder (Flood 1 to Flood 5)\n",
    "for flood_folder in sorted(os.listdir(root_dir)):\n",
    "    flood_path = os.path.join(root_dir, flood_folder)\n",
    "\n",
    "    if os.path.isdir(flood_path):  # Ensure it's a directory\n",
    "        print(f\"📂 Processing: {flood_folder}\")\n",
    "\n",
    "        # Loop through risk levels (5yr, 25yr, 100yr)\n",
    "        for risk_period in output_files.keys():\n",
    "            risk_path = os.path.join(flood_path, risk_period)\n",
    "\n",
    "            if os.path.isdir(risk_path):  # Ensure it exists\n",
    "                print(f\"  ⏳ Processing Risk Period: {risk_period}\")\n",
    "\n",
    "                # Placeholder for batch processing\n",
    "                all_gdfs = []\n",
    "                province_counter = 0  # Track processed provinces\n",
    "\n",
    "                # Loop through province folders inside risk period\n",
    "                for province in sorted(os.listdir(risk_path)):\n",
    "                    province_path = os.path.join(risk_path, province)\n",
    "\n",
    "                    if os.path.isdir(province_path):  # Ensure it's a province folder\n",
    "                        print(f\"    🏙 Processing Province: {province}\")\n",
    "\n",
    "                        # Find the shapefile inside the province folder\n",
    "                        shapefiles = glob.glob(os.path.join(province_path, \"*.shp\"))\n",
    "\n",
    "                        for shp in shapefiles:\n",
    "                            if test_limit is not None and processed_count >= test_limit:\n",
    "                                break  # Stop after reaching test limit\n",
    "\n",
    "                            print(f\"      📂 Reading file: {shp}\")\n",
    "\n",
    "                            try:\n",
    "                                # Load shapefile\n",
    "                                gdf = gpd.read_file(shp)\n",
    "\n",
    "                                # Rename 'Var' to 'FloodRisk'\n",
    "                                gdf = gdf.rename(columns={\"Var\": \"FloodRisk\"})\n",
    "\n",
    "                                # Add metadata: Province and Flood Return Period\n",
    "                                gdf[\"Province\"] = province\n",
    "                                gdf[\"FloodReturnPeriod\"] = risk_period\n",
    "\n",
    "                                # Collect data for batch processing\n",
    "                                all_gdfs.append(gdf)\n",
    "                                processed_count += 1\n",
    "                                province_counter += 1\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"      ❌ Error processing {shp}: {e}\")\n",
    "\n",
    "                    # **Save after every 10 provinces**\n",
    "                    if province_counter >= SAVE_INTERVAL:\n",
    "                        if all_gdfs:\n",
    "                            combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "                            parquet_path = output_files[risk_period]\n",
    "\n",
    "                            # Append by reading old data and merging before saving\n",
    "                            if os.path.exists(parquet_path):\n",
    "                                old_gdf = gpd.read_parquet(parquet_path)\n",
    "                                combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "                            # Save\n",
    "                            combined_gdf.to_parquet(parquet_path, index=False)\n",
    "                            print(f\"      ✅ Saved {province_counter} provinces to {parquet_path}\")\n",
    "\n",
    "                            # Reset buffer\n",
    "                            all_gdfs = []\n",
    "                            province_counter = 0\n",
    "\n",
    "                # **Final save if any data remains**\n",
    "                if all_gdfs:\n",
    "                    combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "                    parquet_path = output_files[risk_period]\n",
    "\n",
    "                    if os.path.exists(parquet_path):\n",
    "                        old_gdf = gpd.read_parquet(parquet_path)\n",
    "                        combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "                    combined_gdf.to_parquet(parquet_path, index=False)\n",
    "                    print(f\"      ✅ Final save for {risk_period} at {parquet_path}\")\n",
    "\n",
    "# Final message\n",
    "print(\"✅ Incremental processing with auto-saving complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging WITH Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Flood Group: 1\n",
      "📂 Processing: Flood 2\n",
      "Skipping Risk Level: 5\n",
      "Skipping Risk Level: 25\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "Skipping Province: Abra\n",
      "Skipping Province: AgusanDelNorte\n",
      "Skipping Province: Aklan\n",
      "Skipping Province: Apayao\n",
      "Skipping Province: Batangas\n",
      "Skipping Province: Benguet\n",
      "Skipping Province: CamarinesSur\n",
      "Skipping Province: Camiguin\n",
      "Skipping Province: Catanduanes\n",
      "Skipping Province: Cebu\n",
      "Skipping Province: CompostelaValley\n",
      "Skipping Province: DavaoDelNorte\n",
      "Reached start province: DavaoDelSur\n",
      "    🏙 Processing Province: DavaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DavaoDelSur/DavaoDelSur_Flood_100year.shp\n",
      "    🏙 Processing Province: DavaoOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DavaoOccidental/DavaoOccidental_Flood_100year.shp\n",
      "    🏙 Processing Province: DinagatIslands\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/DinagatIslands/DinagatIslands_Flood_100year.shp\n",
      "    🏙 Processing Province: Kalinga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Kalinga/Kalinga_Flood_100year.shp\n",
      "    🏙 Processing Province: Laguna\n",
      "    🏙 Processing Province: LanaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/LanaoDelNorte/LanaoDelNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: LanaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/LanaoDelSur/LanaoDelSur_Flood_100year.shp\n",
      "    🏙 Processing Province: Leyte\n",
      "    🏙 Processing Province: Maguindanao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Maguindanao/Maguindanao_Flood_100year.shp\n",
      "    🏙 Processing Province: Marinduque\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Marinduque/Marinduque_Flood_100year.shp\n",
      "    🏙 Processing Province: MetroManila\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/MetroManila/MetroManila_Flood_100year.shp\n",
      "🔄 Converting CRS from EPSG:32651 to EPSG:4326\n",
      "    🏙 Processing Province: Misamis Oriental\n",
      "    🏙 Processing Province: MisamisOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/MisamisOccidental/MisamisOccidental_Flood_100year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "    🏙 Processing Province: MountainProvince\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/MountainProvince/MountainProvince_Flood_100year.shp\n",
      "    🏙 Processing Province: NegrosOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/NegrosOccidental/NegrosOccidental_Flood_100year.shp\n",
      "    🏙 Processing Province: NuevaVizcaya\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/NuevaVizcaya/NuevaVizcaya_Flood_100year.shp\n",
      "    🏙 Processing Province: OccidentalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/OccidentalMindoro/OccidentalMindoro_Flood_100year.shp\n",
      "    🏙 Processing Province: OrientalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/OrientalMindoro/OrientalMindoro_Flood_100year.shp\n",
      "    🏙 Processing Province: Pangasinan\n",
      "    🏙 Processing Province: Sarangani\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Sarangani/Sarangani_Flood_100year.shp\n",
      "    🏙 Processing Province: SouthCotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/SouthCotabato/SouthCotabato_Flood_100year.shp\n",
      "    🏙 Processing Province: SultanKudarat\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/SultanKudarat/SultanKudarat_Flood_100year.shp\n",
      "    🏙 Processing Province: SurigaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/SurigaoDelNorte/SurigaoDelNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: SurigaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/SurigaoDelSur/SurigaoDelSur_Flood_100year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "    🏙 Processing Province: ZamboangaSibugay\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/ZamboangaSibugay/ZamboangaSibugay_Flood_100year.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "📂 Processing: Flood 3\n",
      "  ⏳ Processing Risk Period: 5yr\n",
      "    🏙 Processing Province: Aurora\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/5yr/Aurora/Aurora_Flood_5year.shp\n",
      "    🏙 Processing Province: DinagatIslands\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/5yr/DinagatIslands/DinagatIslands_Flood_5year.shp\n",
      "    🏙 Processing Province: LanaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/5yr/LanaoDelSur/LanaoDelSur_Flood_5year.shp\n",
      "    🏙 Processing Province: NuevaVizcaya\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/5yr/NuevaVizcaya/NuevaVizcaya_Flood_5year.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "  ⏳ Processing Risk Period: 25yr\n",
      "    🏙 Processing Province: Cagayan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/25yr/Cagayan/Cagayan_Flood_25year.shp\n",
      "      ✅ Final save for 25yr at ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "    🏙 Processing Province: Antique\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Antique/Antique_Flood_100year.shp\n",
      "    🏙 Processing Province: Aurora\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Aurora/Aurora_Flood_100year.shp\n",
      "    🏙 Processing Province: Batanes\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Batanes/Batanes_Flood_100year.shp\n",
      "    🏙 Processing Province: Biliran\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Biliran/Biliran_Flood_100year.shp\n",
      "    🏙 Processing Province: Bohol\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Bohol/Bohol_Flood_100year.shp\n",
      "    🏙 Processing Province: Bukidnon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Bukidnon/Bukidnon_Flood_100year.shp\n",
      "    🏙 Processing Province: Cagayan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Cagayan/Cagayan_Flood_100year.shp\n",
      "    🏙 Processing Province: CamarinesNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/CamarinesNorte/CamarinesNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: Capiz\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Capiz/Capiz_Flood_100year.shp\n",
      "    🏙 Processing Province: Cavite\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Cavite/Cavite_Flood_100year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "    🏙 Processing Province: Cotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Cotabato/SouthCotabato_Flood_100year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Cotabato/Cotabato_Flood_100year.shp\n",
      "    🏙 Processing Province: DavaoOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/DavaoOriental/DavaoOriental_Flood_100year.shp\n",
      "    🏙 Processing Province: Isabela\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Isabela/Isabela_Flood_100year.shp\n",
      "    🏙 Processing Province: LaUnion\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/LaUnion/LaUnion_Flood_100year.shp\n",
      "    🏙 Processing Province: Masbate\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Masbate/Masbate_Flood_100year.shp\n",
      "    🏙 Processing Province: MisamisOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/MisamisOriental/MisamisOriental_Flood_100year.shp\n",
      "    🏙 Processing Province: NorthernSamar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/NorthernSamar/NorthernSamar_Flood_100year.shp\n",
      "    🏙 Processing Province: NuevaEcija\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/NuevaEcija/NuevaEcija_Flood_100year.shp\n",
      "    🏙 Processing Province: Palawan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Palawan/Palawan_Flood_100year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "    🏙 Processing Province: Pampanga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Pampanga/Pampanga_Flood_100year.shp\n",
      "    🏙 Processing Province: Quezon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Quezon/Quezon_Flood_100year.shp\n",
      "    🏙 Processing Province: Quirino\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Quirino/Quirino_Flood_100year.shp\n",
      "    🏙 Processing Province: Rizal\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Rizal/Rizal_Flood_100year.shp\n",
      "    🏙 Processing Province: Sorsogon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Sorsogon/Sorsogon_Flood_100year.shp\n",
      "    🏙 Processing Province: SouthernLeyte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/SouthernLeyte/SouthernLeyte_Flood_100year.shp\n",
      "    🏙 Processing Province: Tarlac\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Tarlac/Tarlac_Flood_100year.shp\n",
      "    🏙 Processing Province: Zambales\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/Zambales/Zambales_Flood_100year.shp\n",
      "    🏙 Processing Province: ZamboangaDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 3/100yr/ZamboangaDelNorte/ZamboangaDelNorte_Flood_100year.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "📂 Processing: Flood 4\n",
      "  ⏳ Processing Risk Period: 5yr\n",
      "    🏙 Processing Province: Aklan\n",
      "    🏙 Processing Province: Apayao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Apayao/Apayao_Flood_5year.shp\n",
      "    🏙 Processing Province: Bataan\n",
      "    🏙 Processing Province: Batangas\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Batangas/Batangas_Flood_5yr.shp\n",
      "    🏙 Processing Province: Benguet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Benguet/Benguet_Flood_5year.shp\n",
      "    🏙 Processing Province: Bohol\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Bohol/Bohol_Flood_5year.shp\n",
      "    🏙 Processing Province: Bukidnon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Bukidnon/Bukidnon_Flood_5year.shp\n",
      "    🏙 Processing Province: CamarinesNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/CamarinesNorte/CamarinesNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: CamarinesSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/CamarinesSur/CamarinesSur_Flood_5yr.shp\n",
      "    🏙 Processing Province: Capiz\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Capiz/Capiz_Flood_5year.shp\n",
      "    🏙 Processing Province: Cavite\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Cavite/Cavite_Flood_5year.shp\n",
      "    🏙 Processing Province: Cebu\n",
      "    🏙 Processing Province: CompostelaValley\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/CompostelaValley/CompostelaValley_Flood_5year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "    🏙 Processing Province: Cotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Cotabato/Cotabato_Flood_5year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Cotabato/SouthCotabato_Flood_5year.shp\n",
      "    🏙 Processing Province: DavaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/DavaoDelNorte/DavaoDelNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: DavaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/DavaoDelSur/DavaoDelSur_Flood_5year.shp\n",
      "    🏙 Processing Province: DavaoOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/DavaoOriental/DavaoOriental_Flood_5year.shp\n",
      "    🏙 Processing Province: EasternSamar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/EasternSamar/EasternSamar_Flood_5year.shp\n",
      "    🏙 Processing Province: Laguna\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Laguna/Laguna_Flood_5year.shp\n",
      "    🏙 Processing Province: LanaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/LanaoDelNorte/LanaoDelNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: Leyte\n",
      "    🏙 Processing Province: Maguindanao\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Maguindanao/Maguindanao_Flood_5year.shp\n",
      "    🏙 Processing Province: MetroManila\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/MetroManila/MetroManila_Flood_5year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "    🏙 Processing Province: Misamis Oriental\n",
      "    🏙 Processing Province: NegrosOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/NegrosOccidental/NegrosOccidental_Flood_5year.shp\n",
      "    🏙 Processing Province: NegrosOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/NegrosOriental/NegrosOriental_Flood_5year.shp\n",
      "    🏙 Processing Province: NuevaEcija\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/NuevaEcija/NuevaEcija_Flood_5year.shp\n",
      "    🏙 Processing Province: OccidentalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/OccidentalMindoro/OccidentalMindoro_Flood_5year.shp\n",
      "    🏙 Processing Province: OrientalMindoro\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/OrientalMindoro/OrientalMindoro_Flood_5year.shp\n",
      "    🏙 Processing Province: Palawan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Palawan/Palawan_Flood_5year.shp\n",
      "    🏙 Processing Province: Pangasinan\n",
      "    🏙 Processing Province: Samar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Samar/Samar_Flood_5year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Samar/EasternSamar_Flood_5year.shp\n",
      "    🏙 Processing Province: SouthCotabato\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/SouthCotabato/SouthCotabato_Flood_5year.shp\n",
      "    🏙 Processing Province: SouthernLeyte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/SouthernLeyte/SouthernLeyte_Flood_5year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "    🏙 Processing Province: SultanKudarat\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/SultanKudarat/SultanKudarat_Flood_5year.shp\n",
      "    🏙 Processing Province: SurigaoDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/SurigaoDelNorte/SurigaoDelNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: SurigaoDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/SurigaoDelSur/SurigaoDelSur_Flood_5year.shp\n",
      "    🏙 Processing Province: Zambales\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Zambales/Zambales_Flood_5year.shp\n",
      "    🏙 Processing Province: ZamboangaDelNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/ZamboangaDelNorte/ZamboangaDelNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: ZamboangaDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/ZamboangaDelSur/ZamboangaDelSur_Flood_5year.shp\n",
      "    🏙 Processing Province: ZamboangaSibugay\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/ZamboangaSibugay/ZamboangaSibugay_Flood_5year.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "    🏙 Processing Province: Bulacan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/100yr/Bulacan/Bulacan_Flood_100year.shp\n",
      "    🏙 Processing Province: EasternSamar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/100yr/EasternSamar/EasternSamar_Flood_100year.shp\n",
      "    🏙 Processing Province: IlocosSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/100yr/IlocosSur/IlocosSur_Flood_100year.shp\n",
      "    🏙 Processing Province: Iloilo\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/100yr/Iloilo/Iloilo_Flood_100year.shp\n",
      "    🏙 Processing Province: ZamboangaDelSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/100yr/ZamboangaDelSur/ZamboangaDelSur_Flood_100year.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "📂 Processing: Flood 5\n",
      "  ⏳ Processing Risk Period: 5yr\n",
      "    🏙 Processing Province: Bulacan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Bulacan/Bulacan_Flood_5year.shp\n",
      "    🏙 Processing Province: Cagayan\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Cagayan/Cagayan_Flood_5year.shp\n",
      "    🏙 Processing Province: Catanduanes\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Catanduanes/Catanduanes_Flood_5year.shp\n",
      "    🏙 Processing Province: IlocosNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/IlocosNorte/IlocosNorte_Flood_5year.shp\n",
      "    🏙 Processing Province: IlocosSur\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/IlocosSur/IlocosSur_Flood_5year.shp\n",
      "    🏙 Processing Province: Iloilo\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Iloilo/Iloilo_Flood_5year.shp\n",
      "    🏙 Processing Province: Isabela\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Isabela/Isabela_Flood_5year.shp\n",
      "    🏙 Processing Province: LaUnion\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/LaUnion/LaUnion_Flood_5year.shp\n",
      "    🏙 Processing Province: MisamisOccidental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/MisamisOccidental/MisamisOccidental_Flood_5year.shp\n",
      "    🏙 Processing Province: MisamisOriental\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/MisamisOriental/MisamisOriental_Flood_5year.shp\n",
      "      ✅ Saved 10 provinces to ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "    🏙 Processing Province: Pampanga\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Pampanga/Pampanga_Flood_5year.shp\n",
      "    🏙 Processing Province: Quezon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Quezon/Quezon_Flood_5year.shp\n",
      "    🏙 Processing Province: Rizal\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Rizal/Rizal_Flood_5year.shp\n",
      "    🏙 Processing Province: Sorsogon\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Sorsogon/Sorsogon_Flood_5year.shp\n",
      "    🏙 Processing Province: Tarlac\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/5yr/Tarlac/Tarlac_Flood_5year.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "  ⏳ Processing Risk Period: 100yr\n",
      "    🏙 Processing Province: IlocosNorte\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/100yr/IlocosNorte/IlocosNorte_Flood_100year.shp\n",
      "    🏙 Processing Province: Samar\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/100yr/Samar/NorthernSamar_Flood_100year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/100yr/Samar/Samar_Flood_100year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 5/100yr/Samar/EasternSamar_Flood_100year.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "✅ Incremental processing with auto-saving complete!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Root directories\n",
    "root_dir = \"../00_data/flood_risk/\"\n",
    "output_path = \"../01_processed_data/flood_risk/\"\n",
    "\n",
    "# 📌 Common CRS\n",
    "COMMON_CRS = \"EPSG:4326\"\n",
    "\n",
    "# CHECKPOINT\n",
    "start_with_flood_group = 2\n",
    "start_with_risk_level = 100\n",
    "start_with_province = \"DavaoDelSur\"\n",
    "reached_start = False\n",
    "first_pass = True\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Paths for output files\n",
    "output_files = {\n",
    "    \"5yr\": os.path.join(output_path, \"FloodRisk_5yr.parquet\"),\n",
    "    \"25yr\": os.path.join(output_path, \"FloodRisk_25yr.parquet\"),\n",
    "    \"100yr\": os.path.join(output_path, \"FloodRisk_100yr.parquet\"),\n",
    "}\n",
    "\n",
    "# Processing settings\n",
    "SAVE_INTERVAL = 10  # Save every 10 provinces\n",
    "processed_count = 0\n",
    "test_limit = None  # Set to an integer (e.g., 20) for testing, or None for full processing\n",
    "\n",
    "# Loop through each Flood folder (Flood 1 to Flood 5)\n",
    "for flood_folder in sorted(os.listdir(root_dir)):\n",
    "    flood_path = os.path.join(root_dir, flood_folder)    \n",
    "\n",
    "    if os.path.isdir(flood_path):  # Ensure it's a directory\n",
    "        flood_group = int(flood_folder.split(\" \")[1])  # Extract flood group number\n",
    "\n",
    "        if first_pass and flood_group < start_with_flood_group:\n",
    "            print(f\"Skipping Flood Group: {flood_group}\")\n",
    "            continue  # Skip if before the start group    \n",
    "\n",
    "\n",
    "        print(f\"📂 Processing: {flood_folder}\")\n",
    "\n",
    "        # Loop through risk levels (5yr, 25yr, 100yr)\n",
    "        for risk_period in output_files.keys():\n",
    "            risk_path = os.path.join(flood_path, risk_period)\n",
    "\n",
    "\n",
    "            if os.path.isdir(risk_path):  # Ensure it exists\n",
    "\n",
    "                risk_level = int(risk_period[:-2])  # Extract risk level number\n",
    "                if first_pass and risk_level < int(start_with_risk_level):\n",
    "                    print(f\"Skipping Risk Level: {risk_level}\")\n",
    "                    continue\n",
    "            \n",
    "                print(f\"  ⏳ Processing Risk Period: {risk_period}\")\n",
    "\n",
    "                # Placeholder for batch processing\n",
    "                all_gdfs = []\n",
    "                province_counter = 0  # Track processed provinces\n",
    "\n",
    "                # Loop through province folders inside risk period\n",
    "                for province in sorted(os.listdir(risk_path)):\n",
    "\n",
    "                    \n",
    "\n",
    "                    province_path = os.path.join(risk_path, province)\n",
    "\n",
    "                    if os.path.isdir(province_path):  # Ensure it's a province folder\n",
    "\n",
    "                        if first_pass and not reached_start:\n",
    "                            if province == start_with_province:\n",
    "                                reached_start = True\n",
    "                                first_pass = False\n",
    "                                print(f\"Reached start province: {province}\")\n",
    "                            else:\n",
    "                                print(f\"Skipping Province: {province}\")\n",
    "                                continue  # Skip provinces before the start point\n",
    "\n",
    "                        print(f\"    🏙 Processing Province: {province}\")\n",
    "\n",
    "                        # Find the shapefile inside the province folder\n",
    "                        shapefiles = glob.glob(os.path.join(province_path, \"*.shp\"))\n",
    "\n",
    "                        for shp in shapefiles:\n",
    "                            if test_limit is not None and processed_count >= test_limit:\n",
    "                                break  # Stop after reaching test limit\n",
    "\n",
    "                            print(f\"      📂 Reading file: {shp}\")\n",
    "\n",
    "                            try:\n",
    "                                # Load shapefile\n",
    "                                gdf = gpd.read_file(shp)\n",
    "\n",
    "                                # ✅ Convert CRS if needed\n",
    "                                if gdf.crs != COMMON_CRS:\n",
    "                                    print(f\"🔄 Converting CRS from {gdf.crs} to {COMMON_CRS}\")\n",
    "                                    gdf = gdf.to_crs(COMMON_CRS)\n",
    "\n",
    "                                # Rename 'Var' to 'FloodRisk'\n",
    "                                gdf = gdf.rename(columns={\"Var\": \"FloodRisk\"})\n",
    "\n",
    "                                # Add metadata: Province and Flood Return Period\n",
    "                                gdf[\"Province\"] = province\n",
    "                                gdf[\"FloodReturnPeriod\"] = risk_period\n",
    "\n",
    "                                # Collect data for batch processing\n",
    "                                all_gdfs.append(gdf)\n",
    "                                processed_count += 1\n",
    "                                province_counter += 1\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"      ❌ Error processing {shp}: {e}\")\n",
    "\n",
    "                    # **Save after every 10 provinces**\n",
    "                    if province_counter >= SAVE_INTERVAL:\n",
    "                        if all_gdfs:\n",
    "                            combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "                            parquet_path = output_files[risk_period]\n",
    "\n",
    "                            # Append by reading old data and merging before saving\n",
    "                            if os.path.exists(parquet_path):\n",
    "                                old_gdf = gpd.read_parquet(parquet_path)\n",
    "                                combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "                            # Save\n",
    "                            combined_gdf.to_parquet(parquet_path, index=False)\n",
    "                            print(f\"      ✅ Saved {province_counter} provinces to {parquet_path}\")\n",
    "\n",
    "                            # Reset buffer\n",
    "                            all_gdfs = []\n",
    "                            province_counter = 0\n",
    "\n",
    "                # **Final save if any data remains**\n",
    "                if all_gdfs:\n",
    "                    combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "                    parquet_path = output_files[risk_period]\n",
    "\n",
    "                    if os.path.exists(parquet_path):\n",
    "                        old_gdf = gpd.read_parquet(parquet_path)\n",
    "                        combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "                    combined_gdf.to_parquet(parquet_path, index=False)\n",
    "                    print(f\"      ✅ Final save for {risk_period} at {parquet_path}\")\n",
    "\n",
    "# Final message\n",
    "print(\"✅ Incremental processing with auto-saving complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Empty Folders\n",
    "\n",
    "Some folders have the shapefiles erroneously stored inside another subfolder with the name of the province. \\\n",
    "e.g. ../00_data/flood_risk/Flood 1/100yr/Albay/Albay/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/Albay/Albay/PH050500000_FH_100yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/100yr/Bataan/Bataan/PH030800000_FH_100yr.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Aklan/Aklan/PH060400000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Albay/Albay/PH050500000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Bataan/Bataan/PH030800000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Cebu/Cebu/PH072200000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Leyte/Leyte/PH083700000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Misamis Oriental/Misamis Oriental/PH104300000_FH_25yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 1/25yr/Pangasinan/Pangasinan/PH015500000_FH_25yr.shp\n",
      "      ✅ Final save for 25yr at ../01_processed_data/flood_risk/FloodRisk_25yr.parquet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Aklan/Aklan/PH060400000_FH_100yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Cebu/Cebu/PH072200000_FH_100yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Laguna/Laguna/Laguna_Flood_100year.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Leyte/Leyte/PH083700000_FH_100yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Misamis Oriental/Misamis Oriental/PH104300000_FH_100yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/100yr/Pangasinan/Pangasinan/PH015500000_FH_100yr.shp\n",
      "      ✅ Final save for 100yr at ../01_processed_data/flood_risk/FloodRisk_100yr.parquet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 2/5yr/Albay/Albay/PH050500000_FH_5yr.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Aklan/Aklan/PH060400000_FH_5yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Bataan/Bataan/PH030800000_FH_5yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Cebu/Cebu/PH072200000_FH_5yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Leyte/Leyte/PH083700000_FH_5yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Misamis Oriental/Misamis Oriental/PH104300000_FH_5yr.shp\n",
      "      📂 Reading file: ../00_data/flood_risk/Flood 4/5yr/Pangasinan/Pangasinan/PH015500000_FH_5yr.shp\n",
      "      ✅ Final save for 5yr at ../01_processed_data/flood_risk/FloodRisk_5yr.parquet\n",
      "✅ Incremental processing with auto-saving complete!\n"
     ]
    }
   ],
   "source": [
    "# Check empty folders\n",
    "import os\n",
    "\n",
    "# Define the root directory where the flood risk data is stored\n",
    "root_dir = \"../00_data/flood_risk/\"\n",
    "\n",
    "# List to store empty province folders\n",
    "empty_province_folders = []\n",
    "\n",
    "# Processing settings\n",
    "SAVE_INTERVAL = 10  # Save every 10 provinces\n",
    "processed_count = 0\n",
    "\n",
    "# Paths for output files\n",
    "output_files = {\n",
    "    \"5yr\": os.path.join(output_path, \"FloodRisk_5yr.parquet\"),\n",
    "    \"25yr\": os.path.join(output_path, \"FloodRisk_25yr.parquet\"),\n",
    "    \"100yr\": os.path.join(output_path, \"FloodRisk_100yr.parquet\"),\n",
    "}\n",
    "\n",
    "\n",
    "# Iterate through Flood 1 to Flood 5\n",
    "for flood_group in sorted(os.listdir(root_dir)):\n",
    "    flood_group_path = os.path.join(root_dir, flood_group)\n",
    "    \n",
    "    # Skip if not a directory\n",
    "    if not os.path.isdir(flood_group_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate through return periods (5yr, 25yr, 100yr)\n",
    "    for return_period in sorted(os.listdir(flood_group_path)):\n",
    "        return_period_path = os.path.join(flood_group_path, return_period)\n",
    "        \n",
    "        if not os.path.isdir(return_period_path):\n",
    "            continue\n",
    "\n",
    "        # Placeholder for batch processing\n",
    "        all_gdfs = []\n",
    "        province_counter = 0  # Track processed provinces\n",
    "\n",
    "        # Iterate through province folders\n",
    "        for province in sorted(os.listdir(return_period_path)):\n",
    "            province_path = os.path.join(return_period_path, province)\n",
    "\n",
    "            if not os.path.isdir(province_path):\n",
    "                continue\n",
    "\n",
    "            # Check for .shp files in the province folder\n",
    "            shp_files = [f for f in os.listdir(province_path) if f.endswith(\".shp\")]\n",
    "            \n",
    "            if not shp_files:\n",
    "                # If no shapefile, there is likely another subfolder containing the shapefile\n",
    "\n",
    "                for province2 in sorted(os.listdir(province_path)):\n",
    "                    province2_path = os.path.join(province_path, province2)\n",
    "                    \n",
    "                    if os.path.isdir(province2_path):\n",
    "                        \n",
    "                        # Find the shapefile inside the province folder\n",
    "                        shapefiles = glob.glob(os.path.join(province2_path, \"*.shp\"))\n",
    "\n",
    "                        for shp in shapefiles:\n",
    "\n",
    "                            print(f\"      📂 Reading file: {shp}\")\n",
    "\n",
    "                            try:\n",
    "                                # Load shapefile\n",
    "                                gdf = gpd.read_file(shp)\n",
    "\n",
    "                                # ✅ Convert CRS if needed\n",
    "                                if gdf.crs != COMMON_CRS:\n",
    "                                    print(f\"🔄 Converting CRS from {gdf.crs} to {COMMON_CRS}\")\n",
    "                                    gdf = gdf.to_crs(COMMON_CRS)\n",
    "\n",
    "                                # Rename 'Var' to 'FloodRisk'\n",
    "                                gdf = gdf.rename(columns={\"Var\": \"FloodRisk\"})\n",
    "\n",
    "                                # Add metadata: Province and Flood Return Period\n",
    "                                gdf[\"Province\"] = province2\n",
    "                                gdf[\"FloodReturnPeriod\"] = return_period\n",
    "\n",
    "                                # Collect data for batch processing\n",
    "                                all_gdfs.append(gdf)\n",
    "                                processed_count += 1\n",
    "                                province_counter += 1\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"      ❌ Error processing {shp}: {e}\")\n",
    "\n",
    "            # **Save after every 10 provinces**\n",
    "            if province_counter >= SAVE_INTERVAL:\n",
    "                if all_gdfs:\n",
    "                    combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "                    parquet_path = output_files[return_period]\n",
    "\n",
    "                    # Append by reading old data and merging before saving\n",
    "                    if os.path.exists(parquet_path):\n",
    "                        old_gdf = gpd.read_parquet(parquet_path)\n",
    "                        combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "                    # Save\n",
    "                    combined_gdf.to_parquet(parquet_path, index=False)\n",
    "                    print(f\"      ✅ Saved {province_counter} provinces to {parquet_path}\")\n",
    "\n",
    "                    # Reset buffer\n",
    "                    all_gdfs = []\n",
    "                    province_counter = 0\n",
    "\n",
    "        # **Final save if any data remains**\n",
    "        if all_gdfs:\n",
    "            combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True))\n",
    "            parquet_path = output_files[return_period]\n",
    "\n",
    "            if os.path.exists(parquet_path):\n",
    "                old_gdf = gpd.read_parquet(parquet_path)\n",
    "                combined_gdf = pd.concat([old_gdf, combined_gdf], ignore_index=True)\n",
    "\n",
    "            combined_gdf.to_parquet(parquet_path, index=False)\n",
    "            print(f\"      ✅ Final save for {return_period} at {parquet_path}\")\n",
    "\n",
    "          \n",
    "# Final message\n",
    "print(\"✅ Incremental processing with auto-saving complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Parquet Files and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas as dgpd\n",
    "gdf_flood_5 = dgpd.read_parquet(\"../01_processed_data/flood_risk/FloodRisk_5yr_reprojected.parquet\").compute()\n",
    "gdf_flood_25 = dgpd.read_parquet(\"../01_processed_data/flood_risk/FloodRisk_25yr_reprojected.parquet\").compute()\n",
    "gdf_flood_100 = dgpd.read_parquet(\"../01_processed_data/flood_risk/FloodRisk_100yr_reprojected.parquet\").compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FloodRisk</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON (((759330 910470, 759300 910470, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((759330 910500, 759300 910500, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON (((759540 910950, 759510 910950, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON (((387400 694390, 387390 694390, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((385510 695320, 385500 695320, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((669415 902377.571, 669385 9023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON (((671125 902415, 671095 902415, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205417 1728585 0, 205417 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205427 1728565 0, 205427 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205207 1728975 0, 205197 172...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FloodRisk                                           geometry\n",
       "0          1.0  MULTIPOLYGON (((759330 910470, 759300 910470, ...\n",
       "1          2.0  MULTIPOLYGON (((759330 910500, 759300 910500, ...\n",
       "2          3.0  MULTIPOLYGON (((759540 910950, 759510 910950, ...\n",
       "3          1.0  MULTIPOLYGON (((387400 694390, 387390 694390, ...\n",
       "4          2.0  MULTIPOLYGON (((385510 695320, 385500 695320, ...\n",
       "..         ...                                                ...\n",
       "248        2.0  MULTIPOLYGON (((669415 902377.571, 669385 9023...\n",
       "249        3.0  MULTIPOLYGON (((671125 902415, 671095 902415, ...\n",
       "250        1.0  MULTIPOLYGON Z (((205417 1728585 0, 205417 172...\n",
       "251        2.0  MULTIPOLYGON Z (((205427 1728565 0, 205427 172...\n",
       "252        3.0  MULTIPOLYGON Z (((205207 1728975 0, 205197 172...\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_flood_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Province and FloodReturnPeriod columns\n",
    "gdf_flood_5 = gdf_flood_5.drop(columns=[\"Province\", \"FloodReturnPeriod\"])\n",
    "gdf_flood_25 = gdf_flood_25.drop(columns=[\"Province\", \"FloodReturnPeriod\"])\n",
    "gdf_flood_100 = gdf_flood_100.drop(columns=[\"Province\", \"FloodReturnPeriod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving flood_5_split_parquet files: 100%|██████████| 207/207 [10:08<00:00,  2.94s/it]\n",
      "Saving flood_25_split_parquet files: 100%|██████████| 222/222 [12:06<00:00,  3.27s/it]\n",
      "Saving flood_100_split_parquet files: 100%|██████████| 253/253 [24:59<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def simplify_and_save(single_row, filepath, initial_tolerance=0.001, max_retries=5, size_limit_mb=100):\n",
    "    tolerance = initial_tolerance\n",
    "    for _ in range(max_retries):\n",
    "        simplified = single_row.copy()\n",
    "        simplified[\"geometry\"] = simplified[\"geometry\"].simplify(tolerance=tolerance, preserve_topology=True)\n",
    "        simplified.to_parquet(filepath, index=False)\n",
    "\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        if size_mb <= size_limit_mb:\n",
    "            return tolerance  # success\n",
    "        else:\n",
    "            tolerance *= 2  # try more simplification\n",
    "    return None  # failed to get under size limit\n",
    "\n",
    "def split_gdf_to_files(gdf, output_dir, prefix=\"part\", file_ext=\"parquet\", initial_tolerance=0.001):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results = []\n",
    "\n",
    "    for i, row in tqdm(gdf.iterrows(), total=len(gdf), desc=f\"Saving {output_dir} files\"):\n",
    "        single_row = gpd.GeoDataFrame([row], crs=gdf.crs)\n",
    "        filename = f\"{prefix}_{i:04d}.{file_ext}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        tolerance_used = simplify_and_save(single_row, filepath, initial_tolerance=initial_tolerance)\n",
    "        results.append({\"filename\": filename, \"tolerance_used\": tolerance_used})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example calls\n",
    "results_5 = split_gdf_to_files(gdf_flood_5, \"flood_5_split_parquet\", prefix=\"part\")\n",
    "results_25 = split_gdf_to_files(gdf_flood_25, \"flood_25_split_parquet\", prefix=\"part\")\n",
    "results_100 = split_gdf_to_files(gdf_flood_100, \"flood_100_split_parquet\", prefix=\"part\")\n",
    "\n",
    "# Optional: Save logs\n",
    "results_5.to_csv(\"flood_5_tolerance_log.csv\", index=False)\n",
    "results_25.to_csv(\"flood_25_tolerance_log.csv\", index=False)\n",
    "results_100.to_csv(\"flood_100_tolerance_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Merge Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def merge_parquet_folder(folder_path):\n",
    "    # Get all .parquet files in the folder\n",
    "    parquet_files = sorted(glob(os.path.join(folder_path, \"*.parquet\")))\n",
    "\n",
    "    # Use list comprehension to read each file into a GeoDataFrame\n",
    "    gdfs = [gpd.read_parquet(f) for f in parquet_files]\n",
    "\n",
    "    # Concatenate into one GeoDataFrame\n",
    "    merged_gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True), crs=gdfs[0].crs)\n",
    "    return merged_gdf\n",
    "\n",
    "# Example usage\n",
    "merged_flood_5 = merge_parquet_folder(\"flood_5_split_parquet\")\n",
    "merged_flood_25 = merge_parquet_folder(\"flood_25_split_parquet\")\n",
    "merged_flood_100 = merge_parquet_folder(\"flood_100_split_parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FloodRisk</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON (((759330 910470, 759300 910470, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((759330 910500, 759300 910500, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON (((759540 910950, 759510 910950, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON (((387400 694390, 387390 694390, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((385510 695320, 385500 695320, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON (((669415 902377.571, 669385 9023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON (((671125 902415, 671095 902415, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205417 1728585 0, 205417 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205427 1728565 0, 205427 172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MULTIPOLYGON Z (((205207 1728975 0, 205197 172...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FloodRisk                                           geometry\n",
       "0          1.0  MULTIPOLYGON (((759330 910470, 759300 910470, ...\n",
       "1          2.0  MULTIPOLYGON (((759330 910500, 759300 910500, ...\n",
       "2          3.0  MULTIPOLYGON (((759540 910950, 759510 910950, ...\n",
       "3          1.0  MULTIPOLYGON (((387400 694390, 387390 694390, ...\n",
       "4          2.0  MULTIPOLYGON (((385510 695320, 385500 695320, ...\n",
       "..         ...                                                ...\n",
       "248        2.0  MULTIPOLYGON (((669415 902377.571, 669385 9023...\n",
       "249        3.0  MULTIPOLYGON (((671125 902415, 671095 902415, ...\n",
       "250        1.0  MULTIPOLYGON Z (((205417 1728585 0, 205417 172...\n",
       "251        2.0  MULTIPOLYGON Z (((205427 1728565 0, 205427 172...\n",
       "252        3.0  MULTIPOLYGON Z (((205207 1728975 0, 205197 172...\n",
       "\n",
       "[253 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_flood_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and Save as GeoJSON (some files cant be opened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flood_5_split/part_0141.geojson - 101.27 MB\n",
      "flood_5_split/part_0144.geojson - 136.30 MB\n",
      "flood_5_split/part_0156.geojson - 128.01 MB\n",
      "flood_5_split/part_0198.geojson - 161.39 MB\n",
      "flood_5_split/part_0171.geojson - 167.75 MB\n",
      "flood_5_split/part_0204.geojson - 135.76 MB\n",
      "flood_5_split/part_0091.geojson - 105.86 MB\n",
      "flood_5_split/part_0127.geojson - 115.01 MB\n",
      "flood_5_split/part_0126.geojson - 144.05 MB\n",
      "flood_5_split/part_0106.geojson - 116.33 MB\n",
      "flood_5_split/part_0105.geojson - 169.96 MB\n",
      "flood_5_split/part_0099.geojson - 106.70 MB\n",
      "flood_5_split/part_0102.geojson - 114.95 MB\n",
      "flood_5_split/part_0090.geojson - 168.83 MB\n",
      "flood_5_split/part_0150.geojson - 129.66 MB\n",
      "flood_5_split/part_0048.geojson - 116.16 MB\n",
      "flood_5_split/part_0174.geojson - 122.44 MB\n",
      "\n",
      "Total files exceeding 100MB: 17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory to scan\n",
    "directory = \"flood_5_split\" \n",
    "threshold = 100 * 1024 * 1024  # 100 MB in bytes\n",
    "count = 0\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        try:\n",
    "            size = os.stat(filepath).st_size\n",
    "            if size > threshold:\n",
    "                print(f\"{filepath} - {size / (1024 * 1024):.2f} MB\")\n",
    "                count += 1\n",
    "        except FileNotFoundError:\n",
    "            # In case the file was removed during scanning\n",
    "            continue\n",
    "\n",
    "print(f\"\\nTotal files exceeding 100MB: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flood_25_split/part_0213.geojson - 165.15 MB\n",
      "flood_25_split/part_0123.geojson - 170.22 MB\n",
      "flood_25_split/part_0156.geojson - 142.59 MB\n",
      "flood_25_split/part_0198.geojson - 132.39 MB\n",
      "flood_25_split/part_0219.geojson - 142.37 MB\n",
      "flood_25_split/part_0186.geojson - 180.84 MB\n",
      "flood_25_split/part_0127.geojson - 102.01 MB\n",
      "flood_25_split/part_0069.geojson - 136.58 MB\n",
      "flood_25_split/part_0124.geojson - 131.56 MB\n",
      "flood_25_split/part_0126.geojson - 125.83 MB\n",
      "flood_25_split/part_0157.geojson - 124.42 MB\n",
      "flood_25_split/part_0117.geojson - 109.51 MB\n",
      "flood_25_split/part_0106.geojson - 122.17 MB\n",
      "flood_25_split/part_0216.geojson - 102.82 MB\n",
      "flood_25_split/part_0105.geojson - 171.17 MB\n",
      "flood_25_split/part_0214.geojson - 104.30 MB\n",
      "flood_25_split/part_0199.geojson - 104.56 MB\n",
      "flood_25_split/part_0084.geojson - 109.86 MB\n",
      "flood_25_split/part_0033.geojson - 116.32 MB\n",
      "flood_25_split/part_0174.geojson - 130.67 MB\n",
      "flood_25_split/part_0120.geojson - 119.46 MB\n",
      "\n",
      "Total files exceeding 100MB: 21\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to scan\n",
    "directory = \"flood_25_split\" \n",
    "threshold = 100 * 1024 * 1024  # 100 MB in bytes\n",
    "count = 0\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        try:\n",
    "            size = os.stat(filepath).st_size\n",
    "            if size > threshold:\n",
    "                print(f\"{filepath} - {size / (1024 * 1024):.2f} MB\")\n",
    "                count += 1\n",
    "        except FileNotFoundError:\n",
    "            # In case the file was removed during scanning\n",
    "            continue\n",
    "\n",
    "print(f\"\\nTotal files exceeding 100MB: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flood_100_split/part_0193.geojson - 142.55 MB\n",
      "flood_100_split/part_0108.geojson - 111.67 MB\n",
      "flood_100_split/part_0213.geojson - 200.00 MB\n",
      "flood_100_split/part_0132.geojson - 110.82 MB\n",
      "flood_100_split/part_0239.geojson - 185.90 MB\n",
      "flood_100_split/part_0238.geojson - 242.11 MB\n",
      "flood_100_split/part_0123.geojson - 131.54 MB\n",
      "flood_100_split/part_0202.geojson - 173.72 MB\n",
      "flood_100_split/part_0112.geojson - 131.10 MB\n",
      "flood_100_split/part_0031.geojson - 106.93 MB\n",
      "flood_100_split/part_0087.geojson - 114.76 MB\n",
      "flood_100_split/part_0229.geojson - 105.67 MB\n",
      "flood_100_split/part_0211.geojson - 200.50 MB\n",
      "flood_100_split/part_0171.geojson - 175.62 MB\n",
      "flood_100_split/part_0125.geojson - 107.58 MB\n",
      "flood_100_split/part_0155.geojson - 169.59 MB\n",
      "flood_100_split/part_0227.geojson - 173.72 MB\n",
      "flood_100_split/part_0127.geojson - 133.21 MB\n",
      "flood_100_split/part_0153.geojson - 196.64 MB\n",
      "flood_100_split/part_0250.geojson - 161.03 MB\n",
      "flood_100_split/part_0124.geojson - 199.83 MB\n",
      "flood_100_split/part_0126.geojson - 150.02 MB\n",
      "flood_100_split/part_0168.geojson - 201.84 MB\n",
      "flood_100_split/part_0129.geojson - 136.58 MB\n",
      "flood_100_split/part_0223.geojson - 203.48 MB\n",
      "flood_100_split/part_0063.geojson - 108.98 MB\n",
      "flood_100_split/part_0216.geojson - 164.67 MB\n",
      "flood_100_split/part_0225.geojson - 110.02 MB\n",
      "flood_100_split/part_0025.geojson - 147.39 MB\n",
      "flood_100_split/part_0222.geojson - 168.44 MB\n",
      "flood_100_split/part_0016.geojson - 127.01 MB\n",
      "flood_100_split/part_0192.geojson - 124.52 MB\n",
      "flood_100_split/part_0078.geojson - 195.33 MB\n",
      "flood_100_split/part_0024.geojson - 160.73 MB\n",
      "flood_100_split/part_0166.geojson - 198.78 MB\n",
      "flood_100_split/part_0172.geojson - 106.77 MB\n",
      "flood_100_split/part_0130.geojson - 119.22 MB\n",
      "flood_100_split/part_0045.geojson - 101.07 MB\n",
      "flood_100_split/part_0161.geojson - 160.77 MB\n",
      "flood_100_split/part_0245.geojson - 258.04 MB\n",
      "flood_100_split/part_0226.geojson - 156.68 MB\n",
      "flood_100_split/part_0209.geojson - 182.62 MB\n",
      "flood_100_split/part_0247.geojson - 109.02 MB\n",
      "flood_100_split/part_0246.geojson - 100.40 MB\n",
      "flood_100_split/part_0251.geojson - 107.13 MB\n",
      "flood_100_split/part_0102.geojson - 136.75 MB\n",
      "flood_100_split/part_0244.geojson - 280.28 MB\n",
      "flood_100_split/part_0084.geojson - 113.09 MB\n",
      "flood_100_split/part_0103.geojson - 124.84 MB\n",
      "flood_100_split/part_0030.geojson - 129.88 MB\n",
      "flood_100_split/part_0205.geojson - 116.19 MB\n",
      "flood_100_split/part_0217.geojson - 146.20 MB\n",
      "flood_100_split/part_0220.geojson - 160.77 MB\n",
      "flood_100_split/part_0201.geojson - 156.68 MB\n",
      "flood_100_split/part_0195.geojson - 109.64 MB\n",
      "flood_100_split/part_0079.geojson - 147.68 MB\n",
      "flood_100_split/part_0174.geojson - 169.37 MB\n",
      "flood_100_split/part_0175.geojson - 150.39 MB\n",
      "flood_100_split/part_0158.geojson - 156.39 MB\n",
      "flood_100_split/part_0207.geojson - 203.69 MB\n",
      "flood_100_split/part_0241.geojson - 121.10 MB\n",
      "\n",
      "Total files exceeding 100MB: 61\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to scan\n",
    "directory = \"flood_100_split\" \n",
    "threshold = 100 * 1024 * 1024  # 100 MB in bytes\n",
    "count = 0\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)\n",
    "        try:\n",
    "            size = os.stat(filepath).st_size\n",
    "            if size > threshold:\n",
    "                print(f\"{filepath} - {size / (1024 * 1024):.2f} MB\")\n",
    "                count += 1\n",
    "        except FileNotFoundError:\n",
    "            # In case the file was removed during scanning\n",
    "            continue\n",
    "\n",
    "print(f\"\\nTotal files exceeding 100MB: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0048.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0048.geojson\n",
      "part_0069.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0069.geojson\n",
      "part_0084.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0084.geojson\n",
      "part_0090.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0090.geojson\n",
      "part_0091.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0091.geojson\n",
      "part_0096.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0096.geojson\n",
      "part_0099.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0099.geojson\n",
      "part_0102.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0102.geojson\n",
      "part_0105.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0105.geojson\n",
      "part_0106.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0106.geojson\n",
      "part_0126.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0126.geojson\n",
      "part_0127.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0127.geojson\n",
      "part_0141.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0141.geojson\n",
      "part_0144.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0144.geojson\n",
      "part_0145.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0145.geojson\n",
      "part_0150.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0150.geojson\n",
      "part_0151.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0151.geojson\n",
      "part_0156.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0156.geojson\n",
      "part_0159.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0159.geojson\n",
      "part_0171.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0171.geojson\n",
      "part_0174.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0174.geojson\n",
      "part_0175.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0175.geojson\n",
      "part_0198.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0198.geojson\n",
      "part_0199.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0199.geojson\n",
      "part_0201.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0201.geojson\n",
      "part_0204.geojson is broken. Attempting to simplify and re-save...\n",
      "✔ Fixed: part_0204.geojson\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "# Base folder and DataFrame\n",
    "folder = \"flood_5_split\"\n",
    "\n",
    "# Parameters\n",
    "tolerance = 0.01\n",
    "\n",
    "# Loop over expected filenames\n",
    "for i in tqdm(range(len(gdf_flood_5)), desc=\"Checking GeoJSON files\"):\n",
    "    filename = f\"part_{i:04d}.geojson\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Missing: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    # Try to open with Fiona\n",
    "    try:\n",
    "        with fiona.open(filepath):\n",
    "            pass  # File is readable\n",
    "    except Exception as e:\n",
    "        print(f\"{filename} is broken. Attempting to simplify and re-save...\")\n",
    "\n",
    "        try:\n",
    "            row = gdf_flood_5.loc[i]\n",
    "            simplified_geom = row.geometry.simplify(tolerance=tolerance, preserve_topology=True)\n",
    "            new_gdf = gpd.GeoDataFrame([row], geometry=[simplified_geom], crs=gdf_flood_5.crs)\n",
    "\n",
    "            new_gdf.to_file(filepath, driver=\"GeoJSON\")\n",
    "            print(f\"✔ Fixed: {filename}\")\n",
    "\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Failed to fix {filename}: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  15%|█▍        | 33/222 [00:19<02:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0033.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  15%|█▌        | 34/222 [00:43<24:28,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0033.geojson\n",
      "part_0034.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  16%|█▌        | 35/222 [00:58<31:48, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0034.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  24%|██▍       | 54/222 [01:09<01:23,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0054.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  25%|██▍       | 55/222 [01:24<12:53,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0054.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  31%|███       | 68/222 [01:31<01:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0069.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  32%|███▏      | 70/222 [01:58<13:42,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0069.geojson\n",
      "part_0070.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  32%|███▏      | 71/222 [02:13<18:49,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0070.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  38%|███▊      | 84/222 [02:19<00:58,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0084.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  38%|███▊      | 85/222 [02:43<16:36,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0084.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  46%|████▌     | 102/222 [02:53<00:55,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0105.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  48%|████▊     | 106/222 [03:23<09:28,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0105.geojson\n",
      "part_0106.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  48%|████▊     | 107/222 [03:43<14:35,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0106.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  50%|█████     | 111/222 [03:46<05:45,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0111.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  50%|█████     | 112/222 [04:03<12:35,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0111.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  51%|█████▏    | 114/222 [04:05<07:06,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0117.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  53%|█████▎    | 118/222 [04:27<08:20,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0117.geojson\n",
      "part_0118.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  54%|█████▎    | 119/222 [04:42<11:38,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0118.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  54%|█████▍    | 120/222 [04:43<09:31,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0120.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  55%|█████▍    | 121/222 [05:05<15:36,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0120.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  55%|█████▌    | 123/222 [05:07<09:10,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0123.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  56%|█████▌    | 124/222 [05:37<19:56, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0123.geojson\n",
      "part_0124.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  56%|█████▋    | 125/222 [05:59<23:58, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0124.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  57%|█████▋    | 126/222 [06:00<17:34, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0126.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  57%|█████▋    | 127/222 [06:21<21:59, 13.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0126.geojson\n",
      "part_0127.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  58%|█████▊    | 128/222 [06:37<22:56, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0127.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  70%|███████   | 156/222 [06:50<00:18,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0156.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  71%|███████   | 157/222 [07:20<09:48,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0156.geojson\n",
      "part_0157.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  71%|███████   | 158/222 [07:45<14:46, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0157.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  76%|███████▌  | 168/222 [07:54<00:51,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0168.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  76%|███████▌  | 169/222 [08:14<05:55,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0168.geojson\n",
      "part_0169.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  77%|███████▋  | 170/222 [08:30<08:07,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0169.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  78%|███████▊  | 174/222 [08:33<02:17,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0174.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  79%|███████▉  | 175/222 [08:58<07:30,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0174.geojson\n",
      "part_0175.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  79%|███████▉  | 176/222 [09:16<09:13, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0175.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  81%|████████  | 180/222 [09:20<02:27,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0180.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  82%|████████▏ | 181/222 [09:36<04:53,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0180.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  84%|████████▍ | 186/222 [09:41<01:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0186.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  84%|████████▍ | 187/222 [10:30<09:28, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0186.geojson\n",
      "part_0187.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  85%|████████▍ | 188/222 [10:48<09:29, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0187.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  89%|████████▉ | 198/222 [10:55<00:30,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0198.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  90%|████████▉ | 199/222 [11:22<03:25,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0198.geojson\n",
      "part_0199.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  90%|█████████ | 200/222 [11:41<04:27, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0199.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  96%|█████████▌| 213/222 [11:51<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0213.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  96%|█████████▋| 214/222 [12:22<01:19,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0213.geojson\n",
      "part_0214.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  97%|█████████▋| 215/222 [12:40<01:26, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0214.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  97%|█████████▋| 216/222 [12:41<00:53,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0216.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  98%|█████████▊| 217/222 [13:00<00:58, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0216.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  99%|█████████▊| 219/222 [13:02<00:18,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0219.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  99%|█████████▉| 220/222 [13:34<00:27, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0219.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files: 100%|█████████▉| 221/222 [13:34<00:09,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0221.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files: 100%|██████████| 222/222 [13:50<00:00,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0221.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "# Base folder and DataFrame\n",
    "folder = \"flood_25_split\"\n",
    "\n",
    "# Parameters\n",
    "tolerance = 0.01\n",
    "\n",
    "# Loop over expected filenames\n",
    "for i in tqdm(range(len(gdf_flood_25)), desc=\"Checking GeoJSON files\"):\n",
    "    filename = f\"part_{i:04d}.geojson\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Missing: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    # Try to open with Fiona\n",
    "    try:\n",
    "        with fiona.open(filepath):\n",
    "            pass  # File is readable\n",
    "    except Exception as e:\n",
    "        print(f\"{filename} is broken. Attempting to simplify and re-save...\")\n",
    "\n",
    "        try:\n",
    "            row = gdf_flood_25.loc[i]\n",
    "            simplified_geom = row.geometry.simplify(tolerance=tolerance, preserve_topology=True)\n",
    "            new_gdf = gpd.GeoDataFrame([row], geometry=[simplified_geom], crs=gdf_flood_25.crs)\n",
    "\n",
    "            new_gdf.to_file(filepath, driver=\"GeoJSON\")\n",
    "            print(f\"✔ Fixed: {filename}\")\n",
    "\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Failed to fix {filename}: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:   6%|▋         | 16/253 [00:05<01:46,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0016.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:   7%|▋         | 17/253 [00:27<20:40,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0016.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:   9%|▉         | 24/253 [00:32<04:09,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0024.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  10%|▉         | 25/253 [01:03<37:28,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0024.geojson\n",
      "part_0025.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  10%|█         | 26/253 [01:29<55:59, 14.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0025.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  11%|█         | 28/253 [01:31<29:04,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0028.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  11%|█▏        | 29/253 [01:46<36:39,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0028.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  12%|█▏        | 30/253 [01:47<26:38,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0030.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  12%|█▏        | 31/253 [02:13<47:27, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0030.geojson\n",
      "part_0031.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  13%|█▎        | 32/253 [02:32<54:32, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0031.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  18%|█▊        | 45/253 [02:38<02:37,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0045.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  18%|█▊        | 46/253 [02:58<22:16,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0045.geojson\n",
      "part_0046.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  19%|█▊        | 47/253 [03:13<31:08,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0046.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  25%|██▍       | 63/253 [03:21<01:59,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0063.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  25%|██▌       | 64/253 [03:42<21:07,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0063.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  31%|███       | 78/253 [03:50<01:13,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0078.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  31%|███       | 79/253 [04:25<27:15,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0078.geojson\n",
      "part_0079.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  32%|███▏      | 80/253 [04:50<39:23, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0079.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  33%|███▎      | 83/253 [04:52<16:05,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0084.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  34%|███▎      | 85/253 [05:12<21:01,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0084.geojson\n",
      "part_0085.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  34%|███▍      | 86/253 [05:29<26:32,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0085.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  34%|███▍      | 87/253 [05:30<20:47,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0087.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  35%|███▍      | 88/253 [05:51<29:44, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0087.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  40%|████      | 102/253 [06:02<01:45,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0102.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  41%|████      | 103/253 [06:32<23:31,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0102.geojson\n",
      "part_0103.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  41%|████      | 104/253 [06:59<36:25, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0103.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  43%|████▎     | 108/253 [07:03<10:01,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0108.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  43%|████▎     | 109/253 [07:22<20:59,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0108.geojson\n",
      "part_0109.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  43%|████▎     | 110/253 [07:36<24:35, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0109.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  44%|████▍     | 112/253 [07:39<13:21,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0112.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  45%|████▍     | 113/253 [08:01<24:39, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0112.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  47%|████▋     | 120/253 [08:04<03:05,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0120.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  48%|████▊     | 121/253 [08:17<10:14,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0120.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  49%|████▊     | 123/253 [08:19<06:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0123.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  49%|████▉     | 124/253 [08:43<19:30,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0123.geojson\n",
      "part_0124.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  49%|████▉     | 125/253 [09:22<38:02, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0124.geojson\n",
      "part_0125.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  50%|████▉     | 126/253 [09:41<38:17, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0125.geojson\n",
      "part_0126.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  50%|█████     | 127/253 [10:11<45:04, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0126.geojson\n",
      "part_0127.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  51%|█████     | 128/253 [10:35<46:32, 22.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0127.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  51%|█████     | 129/253 [10:36<33:11, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0129.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  51%|█████▏    | 130/253 [11:03<39:19, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0129.geojson\n",
      "part_0130.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  52%|█████▏    | 131/253 [11:24<40:23, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0130.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  52%|█████▏    | 132/253 [11:26<28:49, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0132.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  53%|█████▎    | 133/253 [11:51<35:18, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0132.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  53%|█████▎    | 135/253 [11:53<18:05,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0135.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  54%|█████▍    | 136/253 [12:08<20:57, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0135.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  58%|█████▊    | 147/253 [12:17<01:33,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0147.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  58%|█████▊    | 148/253 [12:34<09:49,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0147.geojson\n",
      "part_0148.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  59%|█████▉    | 149/253 [12:50<14:59,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0148.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  59%|█████▉    | 150/253 [12:51<10:54,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0150.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  60%|█████▉    | 151/253 [13:05<14:49,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0150.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  60%|██████    | 153/253 [13:07<08:00,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0153.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  61%|██████    | 154/253 [13:45<24:30, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0153.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  61%|██████▏   | 155/253 [13:47<17:33, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0155.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  62%|██████▏   | 156/253 [14:17<26:47, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0155.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  62%|██████▏   | 157/253 [14:18<19:00, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0157.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  62%|██████▏   | 158/253 [14:33<20:16, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0157.geojson\n",
      "part_0158.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  63%|██████▎   | 159/253 [15:01<27:15, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0158.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  64%|██████▎   | 161/253 [15:03<13:54,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0161.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  64%|██████▍   | 162/253 [15:33<23:08, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0161.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  64%|██████▍   | 163/253 [15:34<16:26, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0163.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  65%|██████▍   | 164/253 [15:50<18:43, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0163.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  66%|██████▌   | 166/253 [15:52<09:39,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0166.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  66%|██████▌   | 167/253 [16:27<21:56, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0166.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  66%|██████▋   | 168/253 [16:29<15:44, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0168.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  67%|██████▋   | 170/253 [17:02<17:12, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0168.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  68%|██████▊   | 171/253 [17:03<12:27,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0171.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  68%|██████▊   | 172/253 [17:52<28:08, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0171.geojson\n",
      "part_0172.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  68%|██████▊   | 173/253 [18:13<28:10, 21.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0172.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  69%|██████▉   | 174/253 [18:14<19:51, 15.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0174.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  69%|██████▉   | 175/253 [18:43<25:03, 19.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0174.geojson\n",
      "part_0175.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  70%|██████▉   | 176/253 [19:09<27:04, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0175.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  76%|███████▌  | 192/253 [19:18<00:44,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0192.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  76%|███████▋  | 193/253 [19:40<06:50,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0192.geojson\n",
      "part_0193.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  77%|███████▋  | 194/253 [20:03<11:38, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0193.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  77%|███████▋  | 195/253 [20:05<08:25,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0195.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  77%|███████▋  | 196/253 [20:23<11:03, 11.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0195.geojson\n",
      "part_0196.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  78%|███████▊  | 197/253 [20:38<11:48, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0196.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  78%|███████▊  | 198/253 [20:39<08:24,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0198.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  79%|███████▊  | 199/253 [20:58<10:53, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0198.geojson\n",
      "part_0199.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  79%|███████▉  | 200/253 [21:15<12:06, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0199.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  79%|███████▉  | 201/253 [21:16<08:33,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0201.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  80%|███████▉  | 202/253 [21:43<12:43, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0201.geojson\n",
      "part_0202.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  80%|████████  | 203/253 [22:13<16:07, 19.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0202.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  81%|████████  | 204/253 [22:14<11:23, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0204.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  81%|████████  | 205/253 [22:30<11:39, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0204.geojson\n",
      "part_0205.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  81%|████████▏ | 206/253 [22:51<12:59, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0205.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  82%|████████▏ | 207/253 [22:53<09:09, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0207.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  82%|████████▏ | 208/253 [23:35<15:45, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0207.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  83%|████████▎ | 209/253 [23:36<11:05, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0209.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  83%|████████▎ | 210/253 [24:11<15:06, 21.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0209.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  83%|████████▎ | 211/253 [24:12<10:32, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0211.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  84%|████████▍ | 212/253 [24:48<14:33, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0211.geojson\n",
      "part_0212.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  84%|████████▍ | 213/253 [25:02<12:43, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0212.geojson\n",
      "part_0213.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  85%|████████▍ | 214/253 [25:37<15:35, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0213.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  85%|████████▍ | 215/253 [25:38<10:41, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0215.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  85%|████████▌ | 216/253 [25:52<09:56, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0215.geojson\n",
      "part_0216.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  86%|████████▌ | 217/253 [26:24<12:31, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0216.geojson\n",
      "part_0217.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  86%|████████▌ | 218/253 [26:51<13:13, 22.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0217.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  87%|████████▋ | 220/253 [26:53<06:24, 11.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0220.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  87%|████████▋ | 221/253 [27:23<09:06, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0220.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  88%|████████▊ | 222/253 [27:23<06:18, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0222.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  88%|████████▊ | 223/253 [27:54<08:52, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0222.geojson\n",
      "part_0223.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  89%|████████▊ | 224/253 [28:32<11:27, 23.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0223.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  89%|████████▉ | 225/253 [28:33<07:55, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0225.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  89%|████████▉ | 226/253 [28:50<07:40, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0225.geojson\n",
      "part_0226.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  90%|████████▉ | 227/253 [29:17<08:41, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0226.geojson\n",
      "part_0227.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  90%|█████████ | 228/253 [29:47<09:33, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0227.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  91%|█████████ | 229/253 [29:48<06:33, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0229.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  91%|█████████ | 230/253 [30:09<06:51, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0229.geojson\n",
      "part_0230.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  91%|█████████▏| 231/253 [30:24<06:08, 16.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0230.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  94%|█████████▍| 238/253 [30:31<00:34,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0238.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  94%|█████████▍| 239/253 [31:15<03:28, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0238.geojson\n",
      "part_0239.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  95%|█████████▍| 240/253 [31:47<04:20, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0239.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  95%|█████████▌| 241/253 [31:48<02:52, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0241.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  96%|█████████▌| 242/253 [32:11<03:06, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0241.geojson\n",
      "part_0242.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  96%|█████████▌| 243/253 [32:26<02:43, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0242.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  96%|█████████▋| 244/253 [32:27<01:45, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0244.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  97%|█████████▋| 245/253 [33:28<03:31, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0244.geojson\n",
      "part_0245.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  97%|█████████▋| 246/253 [34:22<04:03, 34.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0245.geojson\n",
      "part_0246.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  98%|█████████▊| 247/253 [34:38<02:55, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0246.geojson\n",
      "part_0247.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  98%|█████████▊| 248/253 [34:59<02:12, 26.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0247.geojson\n",
      "part_0248.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  98%|█████████▊| 249/253 [35:13<01:31, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0248.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  99%|█████████▉| 250/253 [35:14<00:48, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_0250.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files:  99%|█████████▉| 251/253 [35:52<00:45, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0250.geojson\n",
      "part_0251.geojson is broken. Attempting to simplify and re-save...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files: 100%|█████████▉| 252/253 [36:13<00:22, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Fixed: part_0251.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking GeoJSON files: 100%|██████████| 253/253 [36:14<00:00,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "\n",
    "# Base folder and DataFrame\n",
    "folder = \"flood_100_split\"\n",
    "\n",
    "# Parameters\n",
    "tolerance = 0.01\n",
    "\n",
    "# Loop over expected filenames\n",
    "for i in tqdm(range(len(gdf_flood_100)), desc=\"Checking GeoJSON files\"):\n",
    "    filename = f\"part_{i:04d}.geojson\"\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Missing: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    # Try to open with Fiona\n",
    "    try:\n",
    "        with fiona.open(filepath):\n",
    "            pass  # File is readable\n",
    "    except Exception as e:\n",
    "        print(f\"{filename} is broken. Attempting to simplify and re-save...\")\n",
    "\n",
    "        try:\n",
    "            row = gdf_flood_100.loc[i]\n",
    "            simplified_geom = row.geometry.simplify(tolerance=tolerance, preserve_topology=True)\n",
    "            new_gdf = gpd.GeoDataFrame([row], geometry=[simplified_geom], crs=gdf_flood_100.crs)\n",
    "\n",
    "            new_gdf.to_file(filepath, driver=\"GeoJSON\")\n",
    "            print(f\"✔ Fixed: {filename}\")\n",
    "\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Failed to fix {filename}: {e2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import glob\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Adjust the path and extension based on your format (e.g., .geojson, .shp, .parquet)\n",
    "# files = sorted(glob.glob(\"flood_5_split/part_*.geojson\"))  # or \"*.shp\", \"*.parquet\", etc.\n",
    "\n",
    "# # Read and concatenate all individual GeoDataFrames\n",
    "# gdf_list = [gpd.read_file(file) for file in files]\n",
    "# merged_gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True), crs=gdf_list[0].crs)\n",
    "\n",
    "# # Optionally save the merged file\n",
    "# # merged_gdf.to_file(\"merged_output.geojson\", driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import io\n",
    "# import os\n",
    "\n",
    "# def get_gdf_file_size(gdf, driver=\"GeoJSON\"):\n",
    "#     \"\"\"Estimate the file size of a GeoDataFrame in MB.\"\"\"\n",
    "#     buffer = io.BytesIO()\n",
    "#     gdf.to_file(buffer, driver=driver)\n",
    "#     return len(buffer.getvalue()) / (1024 * 1024)\n",
    "\n",
    "# def split_and_save_gdf(gdf, output_dir=\"output\", base_filename=\"part\", max_mb=95, driver=\"GeoJSON\"):\n",
    "#     \"\"\"Split GeoDataFrame into chunks under max_mb and save each to disk.\"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "\n",
    "#     chunks = []\n",
    "#     current_chunk = []\n",
    "#     part_index = 0\n",
    "\n",
    "#     for _, row in gdf.iterrows():\n",
    "#         current_chunk.append(row)\n",
    "#         temp_gdf = gpd.GeoDataFrame(current_chunk, crs=gdf.crs)\n",
    "\n",
    "#         if get_gdf_file_size(temp_gdf, driver=driver) > max_mb:\n",
    "#             # Save previous chunk\n",
    "#             final_gdf = gpd.GeoDataFrame(current_chunk[:-1], crs=gdf.crs)\n",
    "#             file_path = os.path.join(output_dir, f\"{base_filename}_{part_index}.geojson\")\n",
    "#             final_gdf.to_file(file_path, driver=driver)\n",
    "#             print(f\"Saved {file_path} ({get_gdf_file_size(final_gdf):.2f} MB)\")\n",
    "#             part_index += 1\n",
    "#             current_chunk = [row]  # Start new chunk\n",
    "\n",
    "#     # Save last chunk\n",
    "#     if current_chunk:\n",
    "#         final_gdf = gpd.GeoDataFrame(current_chunk, crs=gdf.crs)\n",
    "#         file_path = os.path.join(output_dir, f\"{base_filename}_{part_index}.geojson\")\n",
    "#         final_gdf.to_file(file_path, driver=driver)\n",
    "#         print(f\"Saved {file_path} ({get_gdf_file_size(final_gdf):.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ee 0.2\n",
      "Uninstalling ee-0.2:\n",
      "  Would remove:\n",
      "    /raid/students/ryan/anaconda3/envs/capstone_venv/bin/ee\n",
      "    /raid/students/ryan/anaconda3/envs/capstone_venv/lib/python3.13/site-packages/ee-0.2.dist-info/*\n",
      "    /raid/students/ryan/anaconda3/envs/capstone_venv/lib/python3.13/site-packages/ee/*\n",
      "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood = ee.ImageCollection(\"GLOBAL_FLOOD_DB/MODIS_EVENTS/V1\").select(\"flooded\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ee.image.Image at 0x7f97bf53d1d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
